{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: k-nearest-neighbor (KNN) from scratch\n",
    "In This notebook we write our own k-nearest-neighbor (KNN) from scratch in Python and apply it to predict the survivability on the famous Titanic dataset.\n",
    "\n",
    "### Content\n",
    "1. Data preparation\n",
    "2. Create additional features\n",
    "3. Algorithm creation\n",
    "4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation\n",
    "First lets import the data and generate one set to process all data at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/titanic/train.csv')\n",
    "test = pd.read_csv('../datasets/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['set'], test['set'] = 'train', 'test'\n",
    "combined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "#### First step is to fill missing values and drop columns we will not be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "set               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will not be using Embarked and Cabin for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = combined.drop(['Cabin', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only one Fare price is missing. fill it with the median of his Pclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass = combined.loc[combined.Fare.isnull(), 'Pclass'].values[0]\n",
    "median_fare = combined.loc[combined.Pclass== pclass, 'Fare'].median()\n",
    "combined.loc[combined.Fare.isnull(), 'Fare'] = median_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing ages\n",
    "To fill in the missing ages, we can do something more clever then just take the overal median age. The names contain titles of which some are linked to their age. Master is a younger boy (in general). Lets take the median of each age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select everything before the . as title\n",
    "combined['Title'] = combined['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "combined['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_reduction = {'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', \n",
    "                   'Master': 'Master', 'Don': 'Mr', 'Rev': 'Mr',\n",
    "                   'Dr': 'Mr', 'Mme': 'Miss', 'Ms': 'Miss',\n",
    "                   'Major': 'Mr', 'Lady': 'Mrs', 'Sir': 'Mr',\n",
    "                   'Mlle': 'Miss', 'Col': 'Mr', 'Capt': 'Mr',\n",
    "                   'Countess': 'Mrs','Jonkheer': 'Mr',\n",
    "                   'Dona': 'Mrs'}\n",
    "combined['Title'] = combined['Title'].map(title_reduction)\n",
    "combined['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, age in combined.groupby('Title')['Age'].median().iteritems():\n",
    "    combined.loc[(combined['Title']==title) & (combined['Age'].isnull()), 'Age'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age               0\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              0\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "set               0\n",
       "Title             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting theory I saw here on Kaggle is that there are groups of people, who would help each other. This might affect the survivability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_family_members_survived(dataset, label='family_survival'):\n",
    "    \"\"\"\n",
    "    Check if other family members survived\n",
    "      -> 0 other did not survive\n",
    "      -> 1 at least one other family member survived\n",
    "      -> 0.5 unknown if other members survived or person was alone\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : DataFrame\n",
    "      The sub-dataframe containing the family\n",
    "    \"\"\"\n",
    "    ds = dataset.copy()\n",
    "    if len(dataset) == 1:\n",
    "        ds[label] = 0.5\n",
    "        return ds\n",
    "    result = []\n",
    "    for ix, row in dataset.iterrows():\n",
    "        survived_fraction = dataset.drop(ix)['Survived'].mean()\n",
    "        if np.isnan(survived_fraction):\n",
    "            result.append(0.5)\n",
    "        elif survived_fraction == 0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    ds[label] = result\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['surname'] = combined['Name'].apply(lambda x: x.split(\",\")[0])\n",
    "combined = combined.groupby(['surname', 'Fare']).apply(other_family_members_survived).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data on families can also be extracted from Tickets. Same ticket orders have the same ticket number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.groupby(['Ticket']).apply(lambda x: other_family_members_survived(x, label='family_survival_ticket')).reset_index(drop=True)\n",
    "combined.loc[combined['family_survival'] == 0.5, 'family_survival'] = combined.loc[combined['family_survival'] == 0.5, 'family_survival_ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get family size from Parch and Sibsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['family_size'] = combined['Parch'] + combined['SibSp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN needs numerical features therefore, we will convert them to numbers. In a general sense, binary categorical data can work. For larger categorical groups, it only makes sense when the numerical values itself have meaning. For example, for class levels, the difference between first class and third class actually mean something. On the other hand, if we would convert Embarked to a number, there is no meaning in the difference between embarked 1 and embarked 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Sex'] = LabelEncoder().fit_transform(combined['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First bin the Fare and Age. The groups are choosen arbitrarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Age'] = pd.qcut(combined['Age'], 4, labels=False)\n",
    "combined['Fare'] = pd.qcut(combined['Fare'], 5, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only coluns we will use and scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['Pclass', 'Sex', 'Age', 'Fare', 'family_size', 'family_survival']\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(combined[selected])\n",
    "combined[selected] = scaler.transform(combined[selected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we split the sets back to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined.loc[combined['set'] == 'train'].drop('set', axis=1)\n",
    "test = combined.loc[combined['set'] == 'test'].drop(['set', 'Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "KNN works by finding, as the name suggests, the nearest neighbor. It assumes that classes share similar properties. To compare to points, we have to see them as vectors. Each feature adds to a dimension. Would we only have a single feature it would be the numeric distance between the two points. With two or more features, we need to do something smarter. To create a single number to express the similarity (or distance) we need to agegrate all the features (or dimensions). One way is to use the Euclidean distance, which is the root of the sum of squared distances between all features. There are many other ways to agegrate the feature distances, all with their strengths and weaknesses. For this example, we will use the Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.sqrt(np.sum((vector1 - vector2)**2))\n",
    "\n",
    "# test function\n",
    "vec1 = np.array([3, 0])\n",
    "vec2 = np.array([0, 4])\n",
    "\n",
    "# this is the 3:4:5 triangle and therefore, it should return 5 (Long live Pythagoras)\n",
    "euclidean_distance(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using our distance function we will now find the closest match in our dataset, when providing a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  Survived\n",
       "1  2  2         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A first implementation\n",
    "def get_nearest_neighbor(vector, dataset, number_of_neighbors=1, ignore_cols=['Survived']):\n",
    "    distances = []\n",
    "    for ix, row in dataset.loc[:, ~dataset.columns.isin(ignore_cols)].iterrows():\n",
    "        distance = euclidean_distance(row, vector)\n",
    "        distances.append((distance, ix))\n",
    "    indices = [x[1] for x in sorted(distances, key=lambda x: x[0])]\n",
    "    neighbors = dataset.loc[indices[:number_of_neighbors]]\n",
    "    return neighbors\n",
    "\n",
    "# Another implementation using Pandas\n",
    "def get_nearest_neighbor(vector, dataset, number_of_vectors=1, ignore_cols=['Survived'], not_count_duplicates=False):\n",
    "    ds = dataset.copy()\n",
    "    ds['distance'] = ds.loc[:, ~ds.columns.isin(ignore_cols)].apply(\n",
    "        lambda x: euclidean_distance(x, vector), axis=1)\n",
    "    if not_count_duplicates:\n",
    "        distances = sorted(ds.distance.unique())[:number_of_vectors]\n",
    "        return ds.loc[ds.distance <= max(distances)].drop('distance', axis=1)\n",
    "    return ds.sort_values('distance', ascending=True).head(number_of_vectors).drop('distance', axis=1)\n",
    "        \n",
    "# test function\n",
    "dataset = pd.DataFrame([\n",
    "    {'a': 1, 'b': 1, 'Survived': 1},\n",
    "    {'a': 2, 'b': 2, 'Survived': 1},\n",
    "    {'a': 3, 'b': 3, 'Survived': 0},\n",
    "    {'a': 4, 'b': 4, 'Survived': 0},\n",
    "    {'a': 5, 'b': 5, 'Survived': 0},\n",
    "])\n",
    "vector = pd.Series({'a': 2.5, 'b': 2.5})\n",
    "\n",
    "# should be (2,2) and (3,3) (if keeping track of duplicates)\n",
    "get_nearest_neighbor(vector, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a function to list the nearest neighbors, we need to select the most dominant class of those neighbors to select as our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def predict(vector, dataset, number_of_neighbors=1, y='Survived'):\n",
    "    neighbors = get_nearest_neighbor(vector, dataset, number_of_neighbors)\n",
    "    return round(neighbors[y].mean())\n",
    "\n",
    "# test function\n",
    "print(predict(vector, dataset))\n",
    "print(predict(pd.Series({'a': 4.5, 'b': 4.5}), dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test algorithm on Titanic dataset\n",
    "To test, we select on row from the set and use KNN to find the best candidate. Of course, we will remove that row from the dataset, or we would find a distance of zero as the identical row is in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "Accuracy: 0.8832772166105499\n"
     ]
    }
   ],
   "source": [
    "def predict_dataset(dataset, number_of_neighbors=1):\n",
    "    ds = dataset.copy()\n",
    "    def predict_row(vector, dataset):\n",
    "        subset = dataset.loc[~(dataset.index==vector.name)]\n",
    "        if vector.name % 100 == 0:\n",
    "            print(vector.name)\n",
    "        return int(predict(vector, subset, number_of_neighbors))\n",
    "\n",
    "    ds['predicted'] = ds.loc[:, ds.columns.isin(selected)].apply(\n",
    "        lambda x: predict_row(x, ds), axis=1)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "ds = predict_dataset(train, number_of_neighbors=18)\n",
    "\n",
    "print('Accuracy:', sum(ds['Survived'] == ds['predicted']) / len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We find a accuracy of 88.3% on the training set. Lets now make our test set predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_testset(test_dataset, train_dataset, number_of_neighbors=1):\n",
    "    ds = test_dataset.copy()\n",
    "    select = selected + ['Survived']\n",
    "    \n",
    "    def predict_row(vector, dataset):\n",
    "        if vector.name % 100 == 0:\n",
    "            print(vector.name)\n",
    "        return int(predict(vector, dataset[select], number_of_neighbors))\n",
    "\n",
    "    ds['Survived'] = ds.loc[:, ds.columns.isin(selected)].apply(\n",
    "        lambda x: predict_row(x, train_dataset), axis=1)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "final_test = predict_testset(test, train, number_of_neighbors=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_test[['PassengerId', 'Survived']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[selected]\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 260 candidates, totalling 1300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8804462833833538\n",
      "KNeighborsClassifier(leaf_size=6, n_neighbors=18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1300 out of 1300 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "params = {'n_neighbors':list(range(4,30,1)),\n",
    "         'leaf_size':list(range(1,50,5))}\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid= params, cv = 5,scoring = \"roc_auc\",verbose=1)\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
